{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from configs.config import load_config\n",
    "from dataloaders.dataloader import get_dataloader\n",
    "from models import model, train, validate, test\n",
    "from preprocessing.dataset_split import prepare_and_split\n",
    "from preprocessing.augment_inplace import augment_train_df\n",
    "from Utils import *"
   ],
   "id": "2acd5c7939e4158",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paths",
   "id": "78e630f6b5d056e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "config = load_config(\"configs/default.yaml\")\n",
   "id": "e2598178a4dbc58e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check if working with CUDA or not",
   "id": "af2f780db5fe5da5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else: device = torch.device(\"cpu\")"
   ],
   "id": "d1d0c6f9d3695e39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read in bbox df for crops",
   "id": "abbaabef344b5f11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "crop_bbox_df = pd.read_csv(config.paths.csv_annot)\n",
   "id": "f1200b7e681adaf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_total = crop_bbox_df[\"image_path\"].nunique()\n",
    "n_elig = crop_bbox_df.dropna(subset=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"])[\"image_path\"].nunique()\n",
    "print(f\"Total number of images: {n_total}   Eligible images: {n_elig}\")\n",
    "# Total number of images: 2703   Eligible images: 2061"
   ],
   "id": "baaaa991bbb31753",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Split dataset into Train-Validate-Test",
   "id": "7b13104c29dc284"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df, val_df, test_df, class_names = prepare_and_split(og_df=crop_bbox_df, config=config)",
   "id": "53122af358e5212e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Augment Train Images",
   "id": "4e92f2c9ba88ddd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "images_root = config.paths.images_root",
   "id": "9c0fe6fc07b1d6f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_total_train = train_df[\"image_path\"].nunique()\n",
    "n_elig_train  = train_df.dropna(subset=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"])[\"image_path\"].nunique()\n",
    "n_total_val = val_df[\"image_path\"].nunique()\n",
    "n_elig_val = val_df.dropna(subset=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"])[\"image_path\"].nunique()\n",
    "n_total_test = test_df[\"image_path\"].nunique()\n",
    "n_elig_test = test_df.dropna(subset=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"])[\"image_path\"].nunique()\n",
    "\n",
    "print(f\"Total train images = {n_total_train} Eligible train images = {n_elig_train} \")\n",
    "print(f\"Total val images={n_total_val}  Eligible val images={n_elig_val}\")\n",
    "print(f\"Total test images = {n_total_test}  Eligible test images={n_elig_test}\")\n"
   ],
   "id": "58833ee4a7d67dc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df = augment_train_df(train_df=train_df, images_root=images_root)",
   "id": "9dc6395a2a15d90a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "new_total_train = train_df[\"image_path\"].nunique()\n",
    "new_elig_train = train_df.dropna(subset=[\"xmin\",\"ymin\",\"xmax\",\"ymax\"])[\"image_path\"].nunique()\n",
    "print(f\"New total train images = {new_total_train}  New eligible train images={new_elig_train}\")"
   ],
   "id": "cc4655f714ffce5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load data",
   "id": "a25e377a4dbedc94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_loader, _ = get_dataloader(\n",
    "    data=train_df,\n",
    "    images_root=config.paths.images_root,\n",
    "    class_names=class_names,\n",
    "    batch_size=config.train.batch_size,\n",
    "    num_workers=config.train.num_workers,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n",
    "val_loader, _ = get_dataloader(\n",
    "    data=val_df,\n",
    "    images_root=config.paths.images_root,\n",
    "    class_names=class_names,\n",
    "    batch_size=config.train.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.train.num_workers,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n",
    "test_loader, _ = get_dataloader(\n",
    "    data=test_df,\n",
    "    images_root=config.paths.images_root,\n",
    "    class_names=class_names,\n",
    "    batch_size=config.train.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.train.num_workers,\n",
    "    collate_fn=collate\n",
    ")\n",
    "\n"
   ],
   "id": "f8bd5e5d4d3cffb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get model",
   "id": "e74dc7bb7b6b8c62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cunei_model = model.build_model(\n",
    "    num_classes=len(class_names),\n",
    "    anchor_sizes=config.model.anchor_sizes,\n",
    "    aspect_ratios=config.model.aspect_ratios,\n",
    "    score_thresh=config.model.score_thresh,\n",
    "    nms_thresh=config.model.nms_thresh,\n",
    "    detections_per_img=config.model.detections_per_img,\n",
    "    imagenet_weights=bool(config.model.use_imagenet_weights)\n",
    ")"
   ],
   "id": "a56625f2823e32a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get Validation function",
   "id": "db8240d3f55e81f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_function = validate.validate_loss_factory(val_loader=val_loader, device=device)",
   "id": "c941a87bd72ce087",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Resume Code",
   "id": "b4f7c33f147c1511"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resume_path = getattr(config.train, \"resume\", None)",
   "id": "6c42cb6ca3ae6065",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run Training and Validation",
   "id": "bee7a5705fa0603f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = train.train(\n",
    "    model=cunei_model,\n",
    "    train_loader=train_loader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    val_fn=val_function,\n",
    "    eval_ctx=train.EvalCtx(loader=val_loader, class_names=class_names),\n",
    "    resume_path=resume_path\n",
    ")\n",
    "\n"
   ],
   "id": "41b6f83d38644e58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run Test",
   "id": "983b3463d58f7e8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_root = getattr(config.train, \"ckpt_dir\", getattr(config.train, \"checkpoint_dir\", \"runs\"))\n",
    "best_path = resolve_best_ckpt(run_root=run_root, metric_name=config.train.best_metric)\n",
    "ckpt = torch.load(best_path, map_location=device, weights_only=False)\n",
    "cunei_model.load_state_dict(ckpt[\"model\"])\n",
    "cunei_model.to(device).eval()\n"
   ],
   "id": "f4ab023ea8247609",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sweep_rows, best = sweep_score_thresh(model=cunei_model, loader=val_loader, device=device, iou=0.5, max_batches=None)\n",
    "\n",
    "ths = [r[\"th\"] for r in sweep_rows]\n",
    "P   = [r[\"precision\"] for r in sweep_rows]\n",
    "R   = [r[\"recall\"]    for r in sweep_rows]\n",
    "F1  = [r[\"f1\"]        for r in sweep_rows]\n",
    "\n",
    "cunei_model.score_thresh = best[\"th\"]\n",
    "\n",
    "print(f\"Best F1 at th={best['th']:.2f}: P={best['precision']:.3f} R={best['recall']:.3f} F1={best['f1']:.3f}\")\n"
   ],
   "id": "61877230373057d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rebuild loaders so targets carry \"image_path\"\n",
    "test_loader, _ = get_dataloader(data=test_df, images_root=config.paths.images_root,\n",
    "                                   class_names=class_names, batch_size=config.train.batch_size,\n",
    "                                   shuffle=False, num_workers=config.train.num_workers, collate_fn=collate)\n"
   ],
   "id": "6f8a7fbc94c9c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ds = test_loader.dataset\n",
    "if hasattr(ds, \"groups\"):\n",
    "    names = [name for name, _ in ds.groups]\n",
    "pd.Series(names, name=\"test_image_names\").to_csv(\"outputs/test_image_names.csv\", index=False)"
   ],
   "id": "e0e8cb3b5a448eb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preds = test.run_inference(cunei_model, test_loader, class_names,\n",
    "                      device=device, out_csv=\"test_predictions.csv\",\n",
    "                      score_thresh=cunei_model.score_thresh)\n",
    "\n"
   ],
   "id": "49ca839d8af5be45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gt and matches (IoU=0.5)\n",
    "gt = build_gt_index(test_loader)"
   ],
   "id": "ab23be03a6b0f970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preds_eval, gt_counts = match_predictions(preds, gt, iou_thr=0.5)\n",
    "print(\"TP:\", int(preds_eval[\"tp\"].sum()))\n"
   ],
   "id": "c8f278b8bf0950ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TP = int(preds_eval[\"tp\"].sum())\n",
    "GT_tot = int(sum(gt_counts.values()))\n",
    "Pred_tot = len(preds_eval)\n",
    "\n",
    "FP = max(Pred_tot - TP, 0)\n",
    "FN = max(GT_tot - TP, 0)\n",
    "\n",
    "prec = TP / max(TP + FP, 1)\n",
    "rec  = TP / max(GT_tot, 1)\n",
    "\n",
    "print(f\"TP={TP} FP={FP} FN={FN}  |  Precision@0.5={prec:.3f} Recall@0.5={rec:.3f}\")\n",
    "assert TP <= GT_tot, \"TP exceeds total GT — matching bug\"\n"
   ],
   "id": "803c6442ca0fdfc0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# per-class AP (you can also use evaluate_map which already returns per_class_AP)\n",
    "res50 = evaluate_map(cunei_model, test_loader, class_names, device=device, iou_thr=0.5, max_batches=None)\n",
    "per_class_AP = res50.get(\"per_class_AP\", res50.get(\"per_class_ap\"))\n",
    "map50 = res50.get(\"mAP@0.5\", res50.get(\"mAP\", None))\n",
    "print(f\"Test mAP@0.5: {map50:.3f}\" if map50 is not None else \"mAP not available\")\n"
   ],
   "id": "3040732ee48aa5b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Per-class P/R at your current score_thresh (from matched preds)\n",
    "tp_by = preds_eval.loc[preds_eval[\"tp\"]].groupby(\"label_id\").size()\n",
    "fp_by = preds_eval.loc[~preds_eval[\"tp\"]].groupby(\"label_id\").size()\n",
    "det_by = preds_eval.groupby(\"label_id\").size()\n",
    "\n",
    "tp_by = tp_by.reindex(range(len(class_names)), fill_value=0)\n",
    "fp_by = fp_by.reindex(range(len(class_names)), fill_value=0)\n",
    "det_by = det_by.reindex(range(len(class_names)), fill_value=0)\n",
    "\n",
    "summary_rows = []\n",
    "for cid, cname in enumerate(class_names):\n",
    "    gt_c = int(gt_counts.get(cid, 0))\n",
    "    tp, fp = int(tp_by[cid]), int(fp_by[cid])\n",
    "    prec = tp / max(tp + fp, 1)\n",
    "    rec  = tp / max(gt_c, 1)\n",
    "    ap   = per_class_AP.get(cname, np.nan)  # keys are names\n",
    "    summary_rows.append({\"class\": cname, \"AP@0.5\": ap, \"Precision@0.5\": prec,\n",
    "                 \"Recall@0.5\": rec, \"GT\": gt_c, \"Detections\": int(det_by[cid])})\n",
    "\n",
    "# Overall row\n",
    "TP, FP = int(tp_by.sum()), int(fp_by.sum())\n",
    "GT_tot = int(sum(gt_counts.values()))\n",
    "overall = {\n",
    "    \"class\": \"ALL\",\n",
    "    \"AP@0.5\": float(map50) if map50 is not None else np.nan,\n",
    "    \"Precision@0.5\": TP / max(TP + FP, 1),\n",
    "    \"Recall@0.5\": TP / max(GT_tot, 1),\n",
    "    \"GT\": GT_tot,\n",
    "    \"Detections\": int(det_by.sum()),\n",
    "}\n",
    "summary = pd.DataFrame(summary_rows + [overall])\n",
    "\n",
    "summary[\"class\"] = summary[\"class\"].astype(str)\n",
    "summary_class_view = summary.sort_values(\"class\").reset_index(drop=True)\n",
    "\n",
    "summary_class_view.assign(iou=0.5, score_thresh=cunei_model.score_thresh).to_csv(\"test_summary.csv\", index=False)\n",
    "\n",
    "summary\n",
    "\n"
   ],
   "id": "8c436e4d0438ce03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visuals - train/val",
   "id": "ca8de26501f1d36d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"train\")\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"val_loss\"]], label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"train_cls\"], label=\"train\")\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"val_cls\"]], label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Classification\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"train_reg\"], label=\"train\")\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"val_reg\"]], label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Regression\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"map50\"] if v is not None])\n",
    "plt.title(\"mAP@0.5\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"precision\"] if v is not None])\n",
    "plt.title(\"Precision@0.5\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], [v for v in history[\"recall\"] if v is not None])\n",
    "plt.title(\"Recall@0.5\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "248d67bd9c626776",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visuals - sweep score",
   "id": "1020651505786db8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ths = [r[\"th\"] for r in sweep_rows]\n",
    "P=[r[\"precision\"] for r in sweep_rows]\n",
    "R=[r[\"recall\"] for r in sweep_rows]\n",
    "F1=[r[\"f1\"] for r in sweep_rows]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ths,P,label=\"P\")\n",
    "plt.plot(ths,R,label=\"R\")\n",
    "plt.plot(ths,F1,label=\"F1\")\n",
    "plt.axvline(best[\"th\"],ls=\"--\")\n",
    "plt.legend(); plt.title(\"Val sweep @ IoU=0.5\")\n",
    "plt.xlabel(\"score_thresh\")\n",
    "plt.savefig(\"val_sweep.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "id": "886535a48653a36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visuals - predictions (sin gt)",
   "id": "d2698c859a669322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1) Score histogram\n",
    "plt.figure(); plt.hist(preds[\"score\"], bins=50, range=(0,1)); plt.title(\"Scores\"); plt.xlabel(\"score\"); plt.ylabel(\"#detections\")\n",
    "\n",
    "# 2) Detections per image\n",
    "counts = preds.groupby(\"image_path\").size()\n",
    "plt.figure(); plt.hist(counts, bins=range(1, counts.max()+2)); plt.title(\"Detections per image\"); plt.xlabel(\"#detections\"); plt.ylabel(\"#images\")\n",
    "\n",
    "# 3) Per-class detection counts\n",
    "pc = preds[\"label_name\"].value_counts().sort_values(ascending=False)\n",
    "plt.figure(figsize=(8,3)); pc.plot(kind=\"bar\"); plt.title(\"Per-class detections\"); plt.ylabel(\"#detections\"); plt.tight_layout()\n",
    "\n",
    "# 4) Box area vs score + area histogram\n",
    "w = preds[\"xmax\"] - preds[\"xmin\"]; h = preds[\"ymax\"] - preds[\"ymin\"]; area = (w*h).clip(lower=1)\n",
    "plt.figure(); plt.scatter(np.log10(area), preds[\"score\"], s=5, alpha=0.3); plt.title(\"Score vs log10(area)\"); plt.xlabel(\"log10(area px^2)\"); plt.ylabel(\"score\")\n",
    "plt.figure(); plt.hist(np.sqrt(area), bins=40); plt.title(\"Box size (sqrt area)\"); plt.xlabel(\"pixels\"); plt.ylabel(\"#detections\")\n",
    "\n",
    "# 5) Spatial heatmap of centers\n",
    "cx = (preds[\"xmin\"] + preds[\"xmax\"]) / 2.0\n",
    "cy = (preds[\"ymin\"] + preds[\"ymax\"]) / 2.0\n",
    "H, xedges, yedges = np.histogram2d(cx, cy, bins=50)\n",
    "plt.figure(); plt.imshow(H.T, origin=\"lower\", aspect=\"auto\"); plt.title(\"Detection centre heatmap\"); plt.colorbar(label=\"#detections\")\n",
    "plt.show()\n"
   ],
   "id": "30671f2082367ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visuals (avec gt)",
   "id": "d24ebed1e9061346"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# per-class AP bar chart (sorted)\n",
    "names, aps = zip(*sorted(per_class_AP.items(), key=lambda kv: kv[1], reverse=True))\n",
    "plt.figure(figsize=(9,3))\n",
    "plt.bar(names, aps)\n",
    "plt.xticks(rotation=45, ha=\"right\"); plt.ylabel(\"AP@0.5\"); plt.title(\"Test per-class AP\")\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "id": "87f579b1ac09ba78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PR curves for up to 4 classes (IoU=0.5)\n",
    "lid2name = preds_eval.groupby(\"label_id\")[\"label_name\"].first().to_dict()\n",
    "name2lid = {str(v): int(k) for k, v in lid2name.items()}\n",
    "\n",
    "print(\"pred ids→names:\", lid2name)\n",
    "print(\"unique GT ids :\", sorted({int(c) for g in gt.values() for c in g[\"labels\"].tolist()}))\n",
    "print(\"TP count      :\", int(preds_eval[\"tp\"].sum()))\n"
   ],
   "id": "e1693e6d6099b7db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "id2name = {i: n for i, n in enumerate(class_names)}\n",
    "name2id = {str(n): i for i, n in id2name.items()}\n",
    "\n",
    "top_names = [n for n,_ in sorted(per_class_AP.items(), key=lambda kv: kv[1], reverse=True)[:4]]\n",
    "\n",
    "plt.figure()\n",
    "for cname in top_names:\n",
    "    cid = name2id.get(str(cname))\n",
    "    if cid is None:\n",
    "        print(f\"skip {cname}: no id\")\n",
    "        continue\n",
    "\n",
    "    rec, prec, ap = pr_curve_for_class(preds_eval, gt_counts, class_id=cid)\n",
    "    plt.plot(rec, prec, label=f\"{id2name[cid]} (AP={ap:.2f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR curves @ IoU=0.5\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2eafecff72a1388c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TP IoU histogram @0.5\n",
    "tp_iou = preds_eval.loc[preds_eval[\"tp\"], \"match_iou\"].dropna().to_numpy()\n",
    "if tp_iou.size:\n",
    "    plt.figure()\n",
    "    plt.hist(tp_iou, bins=np.linspace(0.5, 1.0, 21))\n",
    "    plt.xlabel(\"IoU\"); plt.ylabel(\"#TPs\"); plt.title(\"TP IoU histogram @0.5\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"No true positives to plot IoU histogram.\")\n"
   ],
   "id": "5afbdf503dd05bd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TP confusion (GT vs Pred) without recomputing IoU\n",
    "if \"gt_label_id\" not in preds_eval.columns:\n",
    "    preds_eval[\"gt_label_id\"] = pd.NA\n",
    "\n",
    "preds_eval[\"tp\"] = preds_eval[\"tp\"].astype(bool)\n",
    "\n",
    "tp = preds_eval.loc[preds_eval[\"tp\"]].copy()\n",
    "cm = pd.crosstab(tp[\"gt_label_id\"], tp[\"label_id\"], rownames=[\"GT\"], colnames=[\"Pred\"], dropna=False)\n",
    "\n",
    "cm.index = [lid2name.get(i, str(i)) for i in cm.index]\n",
    "cm.columns = [lid2name.get(i, str(i)) for i in cm.columns]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(cm.values, aspect=\"auto\")\n",
    "plt.xticks(range(len(cm.columns)), cm.columns, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(cm.index)), cm.index)\n",
    "plt.title(\"TP confusion (class vs class)\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ee5c82f65a3ba535",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# detection score distribution (all predictions)\n",
    "plt.figure()\n",
    "plt.hist(preds[\"score\"], bins=50, range=(0,1))\n",
    "plt.xlabel(\"score\"); plt.ylabel(\"#detections\"); plt.title(\"Detection scores\")\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "id": "8c39c27a9d9718a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# detections per image\n",
    "dets_per_img = preds.groupby(\"image_path\").size()\n",
    "plt.figure()\n",
    "plt.hist(dets_per_img, bins=range(1, dets_per_img.max()+2))\n",
    "plt.xlabel(\"#detections per image\"); plt.ylabel(\"#images\"); plt.title(\"Detections per image\")\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "id": "2ff4c2a83de6139",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# score vs box size + size histogram\n",
    "w = preds[\"xmax\"] - preds[\"xmin\"]\n",
    "h = preds[\"ymax\"] - preds[\"ymin\"]\n",
    "area = (w*h).clip(lower=1)\n",
    "plt.figure()\n",
    "plt.scatter(np.log10(area), preds[\"score\"], s=5, alpha=0.3)\n",
    "plt.xlabel(\"log10(area px^2)\"); plt.ylabel(\"score\"); plt.title(\"Score vs box area\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(np.sqrt(area), bins=40)\n",
    "plt.xlabel(\"box size (pixels, sqrt area)\"); plt.ylabel(\"#detections\"); plt.title(\"Box size distribution\")\n",
    "plt.tight_layout(); plt.show()\n"
   ],
   "id": "7a0649848d6da44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# spatial heatmap of detection centers (assumes 512×512)\n",
    "cx = (preds[\"xmin\"] + preds[\"xmax\"]) / 2.0\n",
    "cy = (preds[\"ymin\"] + preds[\"ymax\"]) / 2.0\n",
    "H, xe, ye = np.histogram2d(cx, cy, bins=50, range=[[0,512],[0,512]])\n",
    "plt.figure()\n",
    "plt.imshow(H.T, origin=\"lower\", extent=[0,512,0,512], aspect=\"equal\")\n",
    "plt.colorbar(label=\"#detections\")\n",
    "plt.title(\"Detection centre heatmap\"); plt.tight_layout(); plt.show()\n"
   ],
   "id": "b76a14438370ac7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "det = detection_only_counts(preds, gt, iou=0.5)\n",
    "print(det)  # TPd/FPd/FNd\n",
    "print(\" \")\n",
    "\n",
    "cm, acc, per_cls_rec = classification_on_matched(preds, gt, class_names, iou=0.5)\n",
    "if cm is not None:\n",
    "    print(f\"classification-only accuracy on matched boxes: {acc:.3f}\")\n",
    "    print(cm)\n",
    "\n"
   ],
   "id": "77b998f4a6699193",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
